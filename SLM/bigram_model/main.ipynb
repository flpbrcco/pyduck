{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9a6d4a",
   "metadata": {},
   "source": [
    "Setting Up. \n",
    "Making sure that NumPy is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cda3e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.3.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.3.2-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/12.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.5/12.8 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.1/12.8 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.8 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.8 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 11.2 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb95bb",
   "metadata": {},
   "source": [
    "Understanding the basics\n",
    "\n",
    "A language model predicts the next word in a sentence. \n",
    "\n",
    "Keeping things simple and building a bigram model. \n",
    "\n",
    "This means that the model will predict the next word using only the current word.\n",
    "\n",
    "Starting with a short text to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c038e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample Dataset: A slamm text corpus\n",
    "corpus = \"\"\"Artificial Intelligence is the new electricity.\n",
    "Machine learning is the future of AI.\n",
    "AI is transforming industries and shaping the future.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a9621b",
   "metadata": {},
   "source": [
    "Step 3: Preparing the text.\n",
    "\n",
    "First things first, breaking this text into individual words and create a vocabulary (Basic a list of all unique words). \n",
    "\n",
    "This give us something to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d75641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['future.', 'the', 'new', 'learning', 'transforming', 'and', 'is', 'ai', 'future', 'industries', 'intelligence', 'electricity.', 'machine', 'shaping', 'of', 'artificial', 'ai.']\n",
      "Vocabulary Size: 17\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the corpus into words\n",
    "words = corpus.lower().split()\n",
    "\n",
    "# Create a vocabulary of unique words\n",
    "vocab = list(set(words))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"Vocabulary: {vocab}\")\n",
    "print(f\"Vocabulary Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450ea7f",
   "metadata": {},
   "source": [
    "Converting the text to lowercase and splitting into words.\n",
    "\n",
    "After, creating a list of unique words to serve as our vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f8167",
   "metadata": {},
   "source": [
    "Step 4: Map Words to Number\n",
    "\n",
    "Computers work with numbers, not words. \n",
    "\n",
    "So, we'll map each word to an index and create a reverse mapping too (this will help convert them back to words later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a502928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# Convert the words in the corpus to indices\n",
    "corpus_indices = [word_to_idx[word] for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b04e2d",
   "metadata": {},
   "source": [
    "Basically, we're just turning words into numbers that our model can understand.\n",
    "\n",
    "Each word gets its own number, like 'AI' migth become 0, and 'learning' might become 1, depending on the order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49471981",
   "metadata": {},
   "source": [
    "Step 5: Building the model.\n",
    "\n",
    "Now, let's get to the heart of it: building the bigram model.\n",
    "\n",
    "We want to figure out the probability of one word following another.\n",
    "\n",
    "To do that, we'll count how often each pair (bigram) shows up in our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc30c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram probabilities matrix: [[0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      "  0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      "  0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      " [0.31861199 0.00315457 0.31861199 0.00315457 0.00315457 0.00315457\n",
      "  0.00315457 0.00315457 0.31861199 0.00315457 0.00315457 0.00315457\n",
      "  0.00315457 0.00315457 0.00315457 0.00315457 0.00315457]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.86324786\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.86324786 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.86324786 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.86324786 0.00854701 0.00854701 0.00854701]\n",
      " [0.00315457 0.6340694  0.00315457 0.00315457 0.31861199 0.00315457\n",
      "  0.00315457 0.00315457 0.00315457 0.00315457 0.00315457 0.00315457\n",
      "  0.00315457 0.00315457 0.00315457 0.00315457 0.00315457]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.86324786 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.86324786 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.86324786\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.86324786 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.86324786 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.86324786 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.86324786 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.86324786]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.86324786 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]\n",
      " [0.00854701 0.00854701 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.86324786 0.00854701 0.00854701 0.00854701 0.00854701\n",
      "  0.00854701 0.00854701 0.00854701 0.00854701 0.00854701]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize bigram counts matrix\n",
    "bigram_counts = np.zeros((vocab_size, vocab_size))\n",
    "\n",
    "# Count ocurrences of each bigram in the corpus\n",
    "for i in range(len(corpus_indices) -1):\n",
    "    current_word = corpus_indices[i]\n",
    "    next_word = corpus_indices[i + 1]\n",
    "    bigram_counts[current_word, next_word] += 1\n",
    "\n",
    "# Apply Laplace smoothing by adding 1 to all bigram counts\n",
    "bigram_counts += 0.01\n",
    "\n",
    "# Normalize the counts to get probabilities\n",
    "bigram_probabilities = bigram_counts / bigram_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "print(\"Bigram probabilities matrix:\", bigram_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af22c0",
   "metadata": {},
   "source": [
    "What is happening?\n",
    "\n",
    "Counting how often each word follows another (that's the bigram).\n",
    "\n",
    "Then, turn those counts into probabilities by normalizing them.\n",
    "\n",
    "In simple terms, this means that if 'AI' is often followed by 'is', the probability for that pair will be higher.\n",
    "\n",
    "PS: Laplace smoothing with 'bigram_count += 0.01', an adjustment to avoid zero probabilities when certain words pairs don't appear in the corpus. This ensures that every word pair has a slightly positive probability, even if it's rare, and helps prevent issues like division errors during the normalization process. By using a smaller value like 0.01, we strike a balance between avoiding zeros and not overly inflating probabilities for unseen word pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcee0d",
   "metadata": {},
   "source": [
    "Step 6: Predicting the next word\n",
    "\n",
    "Testing our model by making it predict the next word based on any given word. We do this by sampling from the probability distribuition of the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3ced62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given 'ai', the model predicts 'is'.\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(current_word, bigram_probabilities):\n",
    "    word_idx = word_to_idx[current_word]\n",
    "    next_word_probs = bigram_probabilities[word_idx]\n",
    "    next_word_idx = np.random.choice(range(vocab_size), p=next_word_probs)\n",
    "    return idx_to_word[next_word_idx]\n",
    "\n",
    "# Test the model with a word\n",
    "current_word = 'ai'\n",
    "next_word = predict_next_word(current_word, bigram_probabilities)\n",
    "print(f\"Given '{current_word}', the model predicts '{next_word}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74273aaf",
   "metadata": {},
   "source": [
    "This function takes a word, looks up it's probabilities, and randomly selects the next word based on those probabilities.\n",
    "\n",
    "If you pass in 'AI', the model might predict something like 'is' as the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0ad1a",
   "metadata": {},
   "source": [
    "Step 7: Generate a Sentence\n",
    "\n",
    "Finally, let's generate a whole sentence! We'll start with a word and keep predicting the next word a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b2ea758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentence: artificial intelligence is the new electricity. machine learning shaping the future\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(start_word, bigram_probabilities, length=5):\n",
    "    sentence = [start_word]\n",
    "    current_word = start_word\n",
    "    \n",
    "    for _ in range(length):\n",
    "        next_word = predict_next_word(current_word, bigram_probabilities)\n",
    "        sentence.append(next_word)\n",
    "        current_word = next_word\n",
    "    \n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Generate a sentence starting with 'artificial'\n",
    "generated_sentence = generate_sentence('artificial', bigram_probabilities, length=10)\n",
    "print(f\"Generated sentence: {generated_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbdfa81",
   "metadata": {},
   "source": [
    "This function takes an initial word and predicts the next one, than uses that word to predict the following one, and so on.\n",
    "\n",
    "Before you know it, you've got a full sequence!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigram_model (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
